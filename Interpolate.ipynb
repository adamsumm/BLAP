{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "with open('./sampled_files.txt') as infile:\n",
    "    for line in infile:\n",
    "        segments.append(line.rstrip())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = {}\n",
    "vocab = set([';','{'])\n",
    "for file in segments:\n",
    "    with open(file) as input_file:\n",
    "        level = []\n",
    "        for row in input_file:\n",
    "            level.append(list(row.rstrip()))\n",
    "            vocab |= set(row.rstrip())\n",
    "        levels[file] = level\n",
    "\n",
    "v2i = {v:i for i,v in enumerate(sorted(vocab))}\n",
    "i2v = {i:v for v,i in v2i.items()}\n",
    "\n",
    "\n",
    "t_levels = {}\n",
    "for file,level in levels.items():\n",
    "    t_level = []\n",
    "    for row in range(len(level[0])):\n",
    "        column = []\n",
    "        for col in range(len(level)):\n",
    "            column.append(level[col][row])\n",
    "        t_level.append(column)\n",
    "    t_levels[file] = t_level\n",
    "    \n",
    "chunks = {}\n",
    "for file,level in t_levels.items():\n",
    "    chunk = level\n",
    "    chunk = [''.join(c) for c in chunk]\n",
    "    chunks[file] = ';'.join(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class RNNVAE(nn.Module):\n",
    "    def __init__(self,e_layers,d_layers,\n",
    "                 dropout,vocab_size,\n",
    "                 enc_size,\n",
    "                 dec_size,latent_size,\n",
    "                 rnn_type):\n",
    "        super(RNNVAE, self).__init__()\n",
    "        self.latent_dim = latent_size\n",
    "        self.enc_size = enc_size\n",
    "        self.dec_size = dec_size\n",
    "        self.embed = nn.Embedding(vocab_size,enc_size)\n",
    "        self.encoder = rnn_type(enc_size,hidden_size=enc_size,\n",
    "                              num_layers=e_layers,batch_first=True,\n",
    "                                dropout=dropout, bidirectional=True)\n",
    "        \n",
    "        self.to_mu = nn.Linear(enc_size*2,latent_size)\n",
    "        self.to_logvar = nn.Linear(enc_size*2,latent_size)\n",
    "        \n",
    "        self.decoder = rnn_type(enc_size+latent_size,hidden_size=dec_size,\n",
    "                              num_layers=d_layers,dropout=dropout,\n",
    "                                batch_first=True,)\n",
    "        self.hidden_to_vocab = nn.Linear(dec_size,vocab_size)\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "    def forward(self,input_sequence,start_tok):\n",
    "        \n",
    "        batch_size, seq_length = input_sequence.size(0), input_sequence.size(1)\n",
    "        device = input_sequence.device\n",
    "        embedded = self.embed(input_sequence)\n",
    "        out , _= self.encoder(embedded)\n",
    "        \n",
    "        f_enc = out[:,0,:out.size()[-1]//2]\n",
    "        r_enc = out[:,-1,out.size()[-1]//2:]\n",
    "        enc = torch.cat((f_enc,r_enc),dim=-1)\n",
    "        mu,logvar = self.to_mu(enc), self.to_logvar(enc)\n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        z = torch.randn([batch_size,self.latent_dim],device=device)\n",
    "        z = z * std + mu       \n",
    "        z = z.repeat(1,seq_length).view(batch_size,seq_length,-1)\n",
    "        dec_inp = torch.cat((\n",
    "             self.embed(torch.ones(batch_size,1,dtype=torch.long,device=device)*start_tok),\n",
    "            embedded[:,:-1,:]),dim=1)        \n",
    "        dec_inp = torch.cat((dec_inp,z),dim=-1)\n",
    "        dec_out, _ =self.decoder(dec_inp)\n",
    "        dec_logit = self.hidden_to_vocab(dec_out)\n",
    "        \n",
    "        loss = self.CE(dec_logit.view(batch_size*seq_length,-1),input_sequence.view(-1))\n",
    "        KL_div =  -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return loss, KL_div, dec_logit\n",
    "    \n",
    "class RNNVAE(nn.Module):\n",
    "    def __init__(self,e_layers,d_layers,\n",
    "                 dropout,vocab_size,\n",
    "                 enc_size,\n",
    "                 dec_size,latent_size,\n",
    "                 rnn_type):\n",
    "        super(RNNVAE, self).__init__()\n",
    "        self.latent_dim = latent_size\n",
    "        self.enc_size = enc_size\n",
    "        self.dec_size = dec_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.embed = nn.Embedding(vocab_size,enc_size)\n",
    "        self.encoder = rnn_type(enc_size,hidden_size=enc_size,\n",
    "                              num_layers=e_layers,batch_first=True,\n",
    "                                dropout=dropout, bidirectional=True)\n",
    "        \n",
    "        self.to_mu = nn.Linear(enc_size*2,latent_size)\n",
    "        self.to_logvar = nn.Linear(enc_size*2,latent_size)\n",
    "        self.latent_to_h = nn.Linear(latent_size,dec_size*d_layers)\n",
    "        self.latent_to_c = nn.Linear(latent_size,dec_size*d_layers)\n",
    "        \n",
    "        self.decoder = rnn_type(enc_size,hidden_size=dec_size,\n",
    "                              num_layers=d_layers,dropout=dropout,\n",
    "                                batch_first=True,)\n",
    "        self.hidden_to_vocab = nn.Linear(dec_size,vocab_size)\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "    def forward(self,input_sequence,start_tok):\n",
    "        \n",
    "        batch_size, seq_length = input_sequence.size(0), input_sequence.size(1)\n",
    "        device = input_sequence.device\n",
    "        embedded = self.embed(input_sequence)\n",
    "        out , _= self.encoder(embedded)\n",
    "        \n",
    "        f_enc = out[:,0,:out.size()[-1]//2]\n",
    "        r_enc = out[:,-1,out.size()[-1]//2:]\n",
    "        enc = torch.cat((f_enc,r_enc),dim=-1)\n",
    "        mu,logvar = self.to_mu(enc), self.to_logvar(enc)\n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        z = torch.randn([batch_size,self.latent_dim],device=device)\n",
    "        z = z * std + mu        \n",
    "        dec_h = self.latent_to_h(z)\n",
    "        dec_h = dec_h.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "        dec_c = self.latent_to_c(z)\n",
    "        dec_c = dec_c.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "\n",
    "        dec_inp = torch.cat((\n",
    "             self.embed(torch.ones(batch_size,1,dtype=torch.long,device=device)*start_tok),\n",
    "            embedded[:,:-1,:]),dim=1)        \n",
    "        if self.rnn_type == nn.LSTM:\n",
    "            dec_out, _ =self.decoder(dec_inp,(dec_h,dec_c))\n",
    "        else:\n",
    "            dec_out, _ =self.decoder(dec_inp,dec_h)\n",
    "            \n",
    "        dec_logit = self.hidden_to_vocab(dec_out)\n",
    "        \n",
    "        loss = self.CE(dec_logit.view(batch_size*seq_length,-1),input_sequence.view(-1))\n",
    "        KL_div =  -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return loss, KL_div, dec_logit\n",
    "    \n",
    "e_layer = 3\n",
    "d_layer = 2\n",
    "e_size = 1024\n",
    "l_size = 128\n",
    "d_size = 256\n",
    "dropout = 0.5\n",
    "rnn_vae = RNNVAE(e_layer,d_layer,dropout,len(vocab),e_size,d_size,l_size,nn.GRU)    \n",
    "\n",
    "#rnn_vae = torch.load('rnn_vae.model')\n",
    "rnn_vae = torch.load(f'rnn_vaeEnc{e_layer}_{e_size}_Dec{d_layer}_{d_size}_Lat{l_size}.model').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_by_game = {}\n",
    "for name,chunk in chunks.items():\n",
    "    name = name.split('/')[1]\n",
    "    game = name.split('_')[0]\n",
    "    id = name.split('_')[1].split('.')[0]\n",
    "    if game not in chunks_by_game:\n",
    "        chunks_by_game[game] = []\n",
    "    chunks_by_game[game].append((name,chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (batch size x vocabulary size)\n",
    "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
    "    \"\"\"\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "        # scatter sorted tensors to original indexing\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(dim=1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "        \n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "def interpolate(self,input_sequence1,input_sequence2,val,start_tok,temp):\n",
    "        \n",
    "    batch_size, seq_length = input_sequence1.size(0), input_sequence1.size(1)\n",
    "    device = input_sequence1.device\n",
    "    embedded1 = self.embed(input_sequence1)\n",
    "    out1 , _= self.encoder(embedded1)\n",
    "\n",
    "    f_enc1 = out1[:,0,:out1.size()[-1]//2]\n",
    "    r_enc1 = out1[:,-1,out1.size()[-1]//2:]\n",
    "    enc1 = torch.cat((f_enc1,r_enc1),dim=-1)\n",
    "    z1 = self.to_mu(enc1)\n",
    "    \n",
    "    \n",
    "    embedded2 = self.embed(input_sequence2)\n",
    "    out2 , _= self.encoder(embedded2)\n",
    "\n",
    "    f_enc2 = out2[:,0,:out2.size()[-1]//2]\n",
    "    r_enc2 = out2[:,-1,out2.size()[-1]//2:]\n",
    "    enc2 = torch.cat((f_enc2,r_enc2),dim=-1)\n",
    "    z2 = self.to_mu(enc2)\n",
    "    \n",
    "    z = z1*val + z2*(1-val)\n",
    "    \n",
    "    dec_h = self.latent_to_h(z)\n",
    "    dec_h = dec_h.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "    dec_c = self.latent_to_c(z)\n",
    "    dec_c = dec_c.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "\n",
    "    dec_inp = self.embed(torch.ones(batch_size,1,dtype=torch.long,device=device)*start_tok)\n",
    "    tokens = []    \n",
    "    scores = []\n",
    "    for ii in range(seq_length):   \n",
    "        if self.rnn_type == nn.LSTM:\n",
    "            dec_out, (dec_h,dec_c) =self.decoder(dec_inp,(dec_h,dec_c))\n",
    "        else:\n",
    "            dec_out, dec_h =self.decoder(dec_inp,dec_h)\n",
    "            \n",
    "        dec_logit = self.hidden_to_vocab(dec_out[:,-1,:]).view(batch_size,-1)\n",
    "        dec_logit = top_k_top_p_filtering(dec_logit,top_k=5)\n",
    "        next_token = torch.multinomial(F.softmax(dec_logit/temp, dim=-1), num_samples=1)\n",
    "        \n",
    "        tokens.append(next_token.detach())\n",
    "        chosen_scores = []\n",
    "        for ii,tok in enumerate(tokens[-1]):\n",
    "            chosen_scores.append(dec_logit[ii,tok].item())\n",
    "        scores.append(chosen_scores)\n",
    "        dec_inp = self.embed(next_token).view(batch_size,1,-1)\n",
    "        #dec_inp =torch.cat((dec_inp,self.embed(next_token)\n",
    "        #    ),dim=1)\n",
    "        \n",
    "\n",
    "    return tokens,scores\n",
    "def prettify(level):\n",
    "    levelstr = ''\n",
    "    level = level.split(';')\n",
    "    \n",
    "    level = [c for c in level if len(c) == len(level[0])]\n",
    "    width = len(level)\n",
    "    height = len(level[0]) \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "\n",
    "            levelstr += level[x][y]\n",
    "        levelstr += '\\n'\n",
    "    return levelstr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from tqdm import tqdm_notebook\n",
    "out_folder = f'gru_interpolation_{l_size}'\n",
    "\n",
    "!mkdir {out_folder}\n",
    "!rm {out_folder}/*\n",
    "seq1s = []\n",
    "seq2s = []\n",
    "level1s = []\n",
    "level2s = []\n",
    "batch_size = 128\n",
    "to_do = 10\n",
    "acceptance_temp = 0.5\n",
    "\n",
    "for game1, game2 in tqdm_notebook(list(itertools.combinations(chunks_by_game.keys(),2))):\n",
    "    for level1 in tqdm_notebook(chunks_by_game[game1][:to_do]):\n",
    "        for level2 in  tqdm_notebook(chunks_by_game[game2][:to_do]):\n",
    "            import numpy as np\n",
    "            import random\n",
    "            seq1 = level1[1]\n",
    "            seq2 = level2[1]\n",
    "\n",
    "            seq1 = [v2i[t] for t in seq1] \n",
    "            seq2 = [v2i[t] for t in seq2]\n",
    "            level1s.append(level1[0])\n",
    "            level2s.append(level2[0])\n",
    "            seq1s.append(seq1)\n",
    "            seq2s.append(seq2)\n",
    "            \n",
    "            if len(seq1s) == batch_size:\n",
    "                input_sequence1 =torch.tensor(seq1s).to(device)\n",
    "                input_sequence2 =torch.tensor(seq2s).to(device)\n",
    "                \n",
    "                for interp in [1.0, 0.75, 0.5, 0.25, 0.0]:\n",
    "                    samples = 5\n",
    "                    best_scores = np.ones(input_sequence1.size()[0])*-np.inf\n",
    "                    best_samples = [None]*input_sequence1.size()[0]\n",
    "                    good = False\n",
    "                    while not good:\n",
    "                        samples -= 1\n",
    "                        good = True\n",
    "                        with torch.no_grad():\n",
    "                            rnn_vae.eval()\n",
    "                            encoded, scores = interpolate(rnn_vae,input_sequence1,input_sequence2,interp,v2i['{'],1.0)\n",
    "                            \n",
    "                        scores = np.array(scores)\n",
    "                        scores = np.mean(scores,axis=0)\n",
    "                        for ii,(sc,be) in enumerate(zip(scores,best_scores)):\n",
    "                            if random.random() < np.exp( (sc - be)/acceptance_temp):\n",
    "                                generation = []\n",
    "                                for batch in encoded:\n",
    "                                    token = batch[ii].item()\n",
    "                                    generation.append(token)\n",
    "                                pretty = prettify(''.join([i2v[t] for t in generation]))\n",
    "                                if len(pretty) < 495:\n",
    "                                    continue\n",
    "                                best_scores[ii] = sc\n",
    "                                best_samples[ii] = pretty\n",
    "                        if np.mean(best_scores) == -np.inf:\n",
    "                            good = False\n",
    "                        good = good and samples <= 0\n",
    "                    \n",
    "                    for lvl1,lvl2,out_level in zip(level1s,level2s,best_samples):\n",
    "                        if interp == 0.0:\n",
    "                            name = f'{out_folder}/{lvl2}-100%.txt'\n",
    "                        elif interp == 1.0:\n",
    "                            name = f'{out_folder}/{lvl1}-100%.txt'\n",
    "                        else:\n",
    "                            name = f'{out_folder}/{lvl1}-{lvl2}-{int(100*interp)}%.txt'\n",
    "                        with open(name,'w') as outfile:\n",
    "                            outfile.write(out_level)\n",
    "\n",
    "\n",
    "                \n",
    "                seq1s = []\n",
    "                seq2s = []\n",
    "                level1s = []\n",
    "                level2s = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence1 =torch.tensor(seq1s).to(device)\n",
    "input_sequence2 =torch.tensor(seq2s).to(device)\n",
    "\n",
    "for interp in [1.0, 0.75, 0.5, 0.25, 0.0]:\n",
    "    samples = 5\n",
    "    best_scores = np.ones(input_sequence1.size()[0])*-np.inf\n",
    "    best_samples = [None]*input_sequence1.size()[0]\n",
    "    good = False\n",
    "    while not good:\n",
    "        samples -= 1\n",
    "        good = True\n",
    "        with torch.no_grad():\n",
    "            rnn_vae.eval()\n",
    "            encoded, scores = interpolate(rnn_vae,input_sequence1,input_sequence2,interp,v2i['{'],1.0)\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        scores = np.mean(scores,axis=0)\n",
    "        for ii,(sc,be) in enumerate(zip(scores,best_scores)):\n",
    "            if random.random() < np.exp( (sc - be)/acceptance_temp):\n",
    "                generation = []\n",
    "                for batch in encoded:\n",
    "                    token = batch[ii].item()\n",
    "                    generation.append(token)\n",
    "                pretty = prettify(''.join([i2v[t] for t in generation]))\n",
    "                if len(pretty) < 495:\n",
    "                    continue\n",
    "                best_scores[ii] = sc\n",
    "                best_samples[ii] = pretty\n",
    "        if np.mean(best_scores) == -np.inf:\n",
    "            good = False\n",
    "        good = good and samples <= 0\n",
    "\n",
    "    for lvl1,lvl2,out_level in zip(level1s,level2s,best_samples):\n",
    "        if interp == 0.0:\n",
    "            name = f'{out_folder}/{lvl2}-100%.txt'\n",
    "        elif interp == 1.0:\n",
    "            name = f'{out_folder}/{lvl1}-100%.txt'\n",
    "        else:\n",
    "            name = f'{out_folder}/{lvl1}-{lvl2}-{int(100*interp)}%.txt'\n",
    "        with open(name,'w') as outfile:\n",
    "            outfile.write(out_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1s = []\n",
    "seq2s = []\n",
    "level1s = []\n",
    "level2s = []\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "for game in tqdm_notebook(chunks_by_game.keys()):\n",
    "    for level1,level2 in tqdm_notebook(list(itertools.combinations(chunks_by_game[game][:to_do],2))):    \n",
    "        \n",
    "        seq1 = level1[1]\n",
    "        seq2 = level2[1]\n",
    "\n",
    "        seq1 = [v2i[t] for t in seq1] \n",
    "        seq2 = [v2i[t] for t in seq2]\n",
    "        level1s.append(level1[0])\n",
    "        level2s.append(level2[0])\n",
    "        print(level1[0],level2[0])\n",
    "        seq1s.append(seq1)\n",
    "        seq2s.append(seq2)\n",
    "\n",
    "        if len(seq1s) == batch_size:\n",
    "            input_sequence1 =torch.tensor(seq1s).to(device)\n",
    "            input_sequence2 =torch.tensor(seq2s).to(device)\n",
    "\n",
    "            for interp in [0.75, 0.5, 0.25]:\n",
    "                samples = 5\n",
    "                best_scores = np.ones(input_sequence1.size()[0])*-np.inf\n",
    "                best_samples = [None]*input_sequence1.size()[0]\n",
    "                good = False\n",
    "                while not good:\n",
    "                    samples -= 1\n",
    "                    good = True\n",
    "                    with torch.no_grad():\n",
    "                        rnn_vae.eval()\n",
    "                        encoded, scores = interpolate(rnn_vae,input_sequence1,input_sequence2,interp,v2i['{'],1.0)\n",
    "\n",
    "                    scores = np.array(scores)\n",
    "                    scores = np.mean(scores,axis=0)\n",
    "                    for ii,(sc,be) in enumerate(zip(scores,best_scores)):\n",
    "                        if random.random() < np.exp( (sc - be)/acceptance_temp):\n",
    "                            generation = []\n",
    "                            for batch in encoded:\n",
    "                                token = batch[ii].item()\n",
    "                                generation.append(token)\n",
    "                            pretty = prettify(''.join([i2v[t] for t in generation]))\n",
    "                            if len(pretty) < 495:\n",
    "                                continue\n",
    "                            best_scores[ii] = sc\n",
    "                            best_samples[ii] = pretty\n",
    "                    if np.mean(best_scores) == -np.inf:\n",
    "                        good = False\n",
    "                    good = good and samples <= 0\n",
    "\n",
    "                for lvl1,lvl2,out_level in zip(level1s,level2s,best_samples):\n",
    "                    name = f'{out_folder}/{lvl1}-{lvl2}-{int(100*interp)}%.txt'\n",
    "                    with open(name,'w') as outfile:\n",
    "                        outfile.write(out_level)\n",
    "                \n",
    "            seq1s = []\n",
    "            seq2s = []\n",
    "            level1s = []\n",
    "            level2s = []\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "for interp in [0.75, 0.5, 0.25]:\n",
    "    samples = 5\n",
    "    best_scores = np.ones(input_sequence1.size()[0])*-np.inf\n",
    "    best_samples = [None]*input_sequence1.size()[0]\n",
    "    good = False\n",
    "    while not good:\n",
    "        samples -= 1\n",
    "        good = True\n",
    "        with torch.no_grad():\n",
    "            rnn_vae.eval()\n",
    "            encoded, scores = interpolate(rnn_vae,input_sequence1,input_sequence2,interp,v2i['{'],1.0)\n",
    "\n",
    "        scores = np.array(scores)\n",
    "        scores = np.mean(scores,axis=0)\n",
    "        for ii,(sc,be) in enumerate(zip(scores,best_scores)):\n",
    "            if random.random() < np.exp( (sc - be)/acceptance_temp):\n",
    "                generation = []\n",
    "                for batch in encoded:\n",
    "                    token = batch[ii].item()\n",
    "                    generation.append(token)\n",
    "                pretty = prettify(''.join([i2v[t] for t in generation]))\n",
    "                if len(pretty) < 495:\n",
    "                    continue\n",
    "                best_scores[ii] = sc\n",
    "                best_samples[ii] = pretty\n",
    "        if np.mean(best_scores) == -np.inf:\n",
    "            good = False\n",
    "        good = good and samples <= 0\n",
    "\n",
    "    for lvl1,lvl2,out_level in zip(level1s,level2s,best_samples):\n",
    "        name = f'{out_folder}/{lvl1}-{lvl2}-{int(100*interp)}%.txt'\n",
    "        with open(name,'w') as outfile:\n",
    "            outfile.write(out_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "seq1 = level1[1]\n",
    "seq2 = level2[1]\n",
    "\n",
    "seq1 = [v2i[t] for t in seq1] \n",
    "seq2 = [v2i[t] for t in seq2]\n",
    "input_sequence1 =torch.tensor([seq1]).to(device)\n",
    "input_sequence2 =torch.tensor([seq2]).to(device)\n",
    "\n",
    "\n",
    "samples = 5\n",
    "\n",
    "rnn_vae.eval()\n",
    "torch.no_grad()\n",
    "acceptance_temp = 1.0\n",
    "print(1)\n",
    "print(prettify(''.join([i2v[t] for t in seq1])))\n",
    "for interp in [0.75, 0.5, 0.25]:\n",
    "    best_score = 0\n",
    "    best_result = []\n",
    "    for ii in range(samples):\n",
    "\n",
    "        results = interpolate(rnn_vae,input_sequence1,input_sequence2,interp,v2i['{'],1.0)\n",
    "        score = np.mean(results[1])\n",
    "        if random.random() < np.exp( (score - best_score)/acceptance_temp):\n",
    "            best_score = score\n",
    "            best_result = [t.item() for t in results[0]]\n",
    "    print(interp)\n",
    "    print(prettify(''.join([i2v[t] for t in best_result])))\n",
    "    \n",
    "print(0)\n",
    "print(prettify(''.join([i2v[t] for t in seq2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
