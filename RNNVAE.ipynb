{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = !ls processed/* -d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2segs = {}\n",
    "for segment in segments:\n",
    "    g = segment.split('/')[1].split('_')[0]\n",
    "    if g not in g2segs:\n",
    "        g2segs[g] = []\n",
    "    g2segs[g].append(segment)\n",
    "max_segs = 0\n",
    "for g in g2segs:\n",
    "    max_segs = max(len(g2segs[g]),max_segs)\n",
    "import random\n",
    "segments = []\n",
    "running_total = 0\n",
    "for g in g2segs:\n",
    "    num_segs = len(g2segs[g])\n",
    "    sampling_prob = max_segs /num_segs \n",
    "    random.shuffle(g2segs[g])\n",
    "    \n",
    "    t = 0\n",
    "    for seg in g2segs[g]:\n",
    "        t += sampling_prob\n",
    "        while t > 0:\n",
    "            t -= 1\n",
    "            segments.append(seg)\n",
    "    print(num_segs,len(segments)-running_total)\n",
    "    running_total = len(segments)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = []\n",
    "vocab = set([';','{'])\n",
    "for ii,file in enumerate(segments):\n",
    "    if ii == 303:\n",
    "        print(file)\n",
    "    with open(file) as input_file:\n",
    "        level = []\n",
    "        for row in input_file:\n",
    "            level.append(list(row.rstrip()))\n",
    "            vocab |= set(row.rstrip())\n",
    "        levels.append(level)\n",
    "print(vocab)\n",
    "\n",
    "v2i = {v:i for i,v in enumerate(sorted(vocab))}\n",
    "i2v = {i:v for v,i in v2i.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_levels = []\n",
    "for ii,level in enumerate(levels):\n",
    "    t_level = []\n",
    "    if len(level) != 15:\n",
    "        print(ii)\n",
    "    for row in range(len(level[0])):\n",
    "        column = []\n",
    "        for col in range(len(level)):\n",
    "            if row == len(level[col]):\n",
    "                print(ii,level)\n",
    "            column.append(level[col][row])\n",
    "        t_level.append(column)\n",
    "    t_levels.append(t_level)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chunks = []\n",
    "for level in t_levels:\n",
    "    chunk = level\n",
    "    chunk = [''.join(c) for c in chunk]\n",
    "    chunks.append(';'.join(chunk))\n",
    "    if len(chunks[-1]) != 511:\n",
    "        print(chunks[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNVAE(nn.Module):\n",
    "    def __init__(self,e_layers,d_layers,\n",
    "                 dropout,vocab_size,\n",
    "                 enc_size,\n",
    "                 dec_size,latent_size,\n",
    "                 rnn_type):\n",
    "        super(RNNVAE, self).__init__()\n",
    "        self.latent_dim = latent_size\n",
    "        self.enc_size = enc_size\n",
    "        self.dec_size = dec_size\n",
    "        self.rnn_type = rnn_type\n",
    "        self.embed = nn.Embedding(vocab_size,enc_size)\n",
    "        self.encoder = rnn_type(enc_size,hidden_size=enc_size,\n",
    "                              num_layers=e_layers,batch_first=True,\n",
    "                                dropout=dropout, bidirectional=True)\n",
    "        \n",
    "        self.to_mu = nn.Linear(enc_size*2,latent_size)\n",
    "        self.to_logvar = nn.Linear(enc_size*2,latent_size)\n",
    "        self.latent_to_h = nn.Linear(latent_size,dec_size*d_layers)\n",
    "        self.latent_to_c = nn.Linear(latent_size,dec_size*d_layers)\n",
    "        \n",
    "        self.decoder = rnn_type(enc_size,hidden_size=dec_size,\n",
    "                              num_layers=d_layers,dropout=dropout,\n",
    "                                batch_first=True,)\n",
    "        self.hidden_to_vocab = nn.Linear(dec_size,vocab_size)\n",
    "        self.CE = nn.CrossEntropyLoss()\n",
    "    def forward(self,input_sequence,start_tok):\n",
    "        \n",
    "        batch_size, seq_length = input_sequence.size(0), input_sequence.size(1)\n",
    "        device = input_sequence.device\n",
    "        embedded = self.embed(input_sequence)\n",
    "        out , _= self.encoder(embedded)\n",
    "        \n",
    "        f_enc = out[:,0,:out.size()[-1]//2]\n",
    "        r_enc = out[:,-1,out.size()[-1]//2:]\n",
    "        enc = torch.cat((f_enc,r_enc),dim=-1)\n",
    "        mu,logvar = self.to_mu(enc), self.to_logvar(enc)\n",
    "        \n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        z = torch.randn([batch_size,self.latent_dim],device=device)\n",
    "        z = z * std + mu        \n",
    "        dec_h = self.latent_to_h(z)\n",
    "        dec_h = dec_h.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "        dec_c = self.latent_to_c(z)\n",
    "        dec_c = dec_c.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "\n",
    "        dec_inp = torch.cat((\n",
    "             self.embed(torch.ones(batch_size,1,dtype=torch.long,device=device)*start_tok),\n",
    "            embedded[:,:-1,:]),dim=1)        \n",
    "        if self.rnn_type == nn.LSTM:\n",
    "            dec_out, _ =self.decoder(dec_inp,(dec_h,dec_c))\n",
    "        else:\n",
    "            dec_out, _ =self.decoder(dec_inp,dec_h)\n",
    "            \n",
    "        dec_logit = self.hidden_to_vocab(dec_out)\n",
    "        \n",
    "        loss = self.CE(dec_logit.view(batch_size*seq_length,-1),input_sequence.view(-1))\n",
    "        KL_div =  -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        return loss, KL_div, dec_logit\n",
    "e_layer = 3\n",
    "d_layer = 2\n",
    "e_size = 1024\n",
    "l_size = 32\n",
    "d_size = 256\n",
    "dropout = 0.5\n",
    "rnn_vae = RNNVAE(e_layer,d_layer,dropout,len(vocab),e_size,d_size,l_size,nn.GRU)  \n",
    "\n",
    "#rnn_vae = torch.load('rnn_vae.model')\n",
    "try:\n",
    "    pass\n",
    "    rnn_vae = torch.load(f'rnn_vaeEnc{e_layer}_{e_size}_Dec{d_layer}_{d_size}_Lat{l_size}.model')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "optimizer = optim.Adam(rnn_vae.parameters(),lr=1e-4)\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(rnn_vae.parameters(),lr=1e-5)\n",
    "from tqdm import tqdm_notebook\n",
    "import random\n",
    "import numpy as np\n",
    "device = 'cuda'\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "show_every = 16\n",
    "rnn_vae.to(device)\n",
    "#rnn_vae.encoder.dropout = 0.10\n",
    "#rnn_vae.decoder.dropout = 0.10\n",
    "rnn_vae.train()\n",
    "warmup = 98\n",
    "ratio = 1\n",
    "use_annealing = False\n",
    "for _ in range(10):\n",
    "    \n",
    "    \n",
    "    annealing_rate = 0.99995\n",
    "    annealing = annealing_rate\n",
    "    if len(losses) > 0:\n",
    "        annealing = 1-ratio*np.mean(losses_[-show_every*2:,1])/np.mean(losses_[-show_every*2:,2])\n",
    "        if annealing < 0:\n",
    "            annealing =1\n",
    "    if not use_annealing:\n",
    "        annealing = annealing_rate\n",
    "    for epoch in tqdm_notebook(range(epochs)):\n",
    "        random.shuffle(chunks)\n",
    "        for batch in tqdm_notebook(range(0,len(chunks),batch_size)):\n",
    "            rnn_vae.train()\n",
    "            rnn_vae.zero_grad()\n",
    "            batch = chunks[batch:batch+batch_size]\n",
    "            batch = [[v2i[t] for t in c] for c in batch]\n",
    "            input_sequence =torch.tensor(batch).to(device)\n",
    "            loss, KL_div, dec_logit = rnn_vae(input_sequence,v2i['{'])\n",
    "            loss_KL_div = loss + KL_div*(1.0-annealing)\n",
    "            losses.append((loss_KL_div.item(),loss.item(),KL_div.item()))\n",
    "            loss_KL_div.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(rnn_vae.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            if len(losses) % show_every == 0:\n",
    "                losses_ = np.array(losses)\n",
    "                print(epoch,np.mean(losses_[-show_every*2:,0]),\n",
    "                      np.mean(losses_[-show_every*2:,1]),\n",
    "                      np.mean(losses_[-show_every*2:,2]))\n",
    "                annealing = 1-ratio*np.mean(losses_[-show_every*2:,1])/np.mean(losses_[-show_every*2:,2])\n",
    "                if annealing < 0:\n",
    "                    annealing =annealing_rate\n",
    "                if not use_annealing:\n",
    "                    annealing = annealing_rate\n",
    "                \n",
    "        if epoch >= warmup:\n",
    "            annealing *= annealing_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(f'mv rnn_vaeEnc{e_layer}_{e_size}_Dec{d_layer}_{d_size}_Lat{l_size}.model rnn_vaeEnc{e_layer}_{e_size}_Dec{d_layer}_{d_size}_Lat{l_size}.model_old')\n",
    "torch.save(rnn_vae, f'rnn_vaeEnc{e_layer}_{e_size}_Dec{d_layer}_{d_size}_Lat{l_size}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, filter_value=-float('Inf')):\n",
    "    \"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n",
    "        Args:\n",
    "            logits: logits distribution shape (batch size x vocabulary size)\n",
    "            top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n",
    "            top_p > 0.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n",
    "                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n",
    "        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n",
    "    \"\"\"\n",
    "    top_k = min(top_k, logits.size(-1))  # Safety check\n",
    "    if top_k > 0:\n",
    "        # Remove all tokens with a probability less than the last token of the top-k\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "\n",
    "        # Remove tokens with cumulative probability above the threshold\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        # Shift the indices to the right to keep also the first token above the threshold\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "        # scatter sorted tensors to original indexing\n",
    "        indices_to_remove = sorted_indices_to_remove.scatter(dim=1, index=sorted_indices, src=sorted_indices_to_remove)\n",
    "        \n",
    "        logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "def autoencode(self,input_sequence,start_tok,temp):\n",
    "        \n",
    "    batch_size, seq_length = input_sequence.size(0), input_sequence.size(1)\n",
    "    device = input_sequence.device\n",
    "    embedded = self.embed(input_sequence)\n",
    "    out , _= self.encoder(embedded)\n",
    "\n",
    "    f_enc = out[:,0,:out.size()[-1]//2]\n",
    "    r_enc = out[:,-1,out.size()[-1]//2:]\n",
    "    enc = torch.cat((f_enc,r_enc),dim=-1)\n",
    "    z = self.to_mu(enc)\n",
    "    dec_h = self.latent_to_h(z)\n",
    "    dec_h = dec_h.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "    dec_c = self.latent_to_c(z)\n",
    "    dec_c = dec_c.view(batch_size,-1, self.dec_size).permute(1,0,2).contiguous()\n",
    "\n",
    "    dec_inp = self.embed(torch.ones(batch_size,1,dtype=torch.long,device=device)*start_tok)\n",
    "    tokens = []    \n",
    "    scores = []\n",
    "    for ii in range(seq_length):   \n",
    "        if self.rnn_type == nn.LSTM:\n",
    "            dec_out, (dec_h,dec_c) =self.decoder(dec_inp,(dec_h,dec_c))\n",
    "        else:\n",
    "            dec_out, dec_h =self.decoder(dec_inp,dec_h)\n",
    "            \n",
    "        dec_logit = self.hidden_to_vocab(dec_out[:,-1,:]).view(batch_size,-1)\n",
    "        dec_logit = top_k_top_p_filtering(dec_logit)\n",
    "        next_token = torch.multinomial(F.softmax(dec_logit/temp, dim=-1), num_samples=1)\n",
    "        \n",
    "        tokens.append(next_token.detach())\n",
    "        chosen_scores = []\n",
    "        for ii,tok in enumerate(tokens[-1]):\n",
    "            chosen_scores.append(dec_logit[ii,tok].item())\n",
    "        scores.append(chosen_scores)\n",
    "        dec_inp = self.embed(next_token).view(batch_size,1,-1)\n",
    "        #dec_inp =torch.cat((dec_inp,self.embed(next_token)\n",
    "        #    ),dim=1)\n",
    "        \n",
    "\n",
    "    return tokens,scores\n",
    "\n",
    "\n",
    "def prettify(level):\n",
    "    levelstr = ''\n",
    "    level = level.split(';')\n",
    "    \n",
    "    level = [c for c in level if len(c) == len(level[0])]\n",
    "    width = len(level)\n",
    "    height = len(level[0]) \n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "\n",
    "            levelstr += level[x][y]\n",
    "        levelstr += '\\n'\n",
    "    return levelstr\n",
    "import numpy as np\n",
    "samples = 3\n",
    "best_scores = np.ones(input_sequence.size()[0])*-np.inf\n",
    "best_samples = [None]*input_sequence.size()[0]\n",
    "for _ in range(samples):\n",
    "    with torch.no_grad():\n",
    "        rnn_vae.eval()\n",
    "        encoded, scores = autoencode(rnn_vae,input_sequence,v2i['{'],0.8)\n",
    "    scores = np.array(scores)\n",
    "    scores = np.mean(scores,axis=0)\n",
    "    for ii,(sc,be) in enumerate(zip(scores,best_scores)):\n",
    "        if sc > be:\n",
    "            best_scores[ii] = sc\n",
    "            generation = []\n",
    "            for batch in encoded:\n",
    "                token = batch[ii].item()\n",
    "                generation.append(token)\n",
    "            best_samples[ii] = prettify(''.join([i2v[t] for t in generation]))\n",
    "    print(best_scores)\n",
    "\n",
    "for b,g in enumerate(best_samples):\n",
    "    print(b)\n",
    "    print('original')\n",
    "    print(prettify(''.join([i2v[t.item()] for t in input_sequence[b,:]])).replace('x','+'))\n",
    "    print('generated')\n",
    "    print(g.replace('x','+'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
